{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                       ### 2.1 SENTENCE SEGMENTATION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Sentence segmentation can be viewed as a classification task for punctuation: \n",
    "whenever we encounter a symbol that could possibly end a sentence, such as a period or a question mark, \n",
    "we have to decide whether it terminates the preceding sentence'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.corpus.treebank_raw.sents()\n",
    "tokens = []\n",
    "boundaries = set()\n",
    "offset = 0\n",
    "for sent in sents:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundaries.add(offset-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START',\n",
       " 'Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we need to specify the features of the data that will be used in order \n",
    "# to decide whether punctuation indicates a sentence-boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct_features(tokens, i):\n",
    "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
    "            'prev-word': tokens[i-1].lower(),\n",
    "            'punct': tokens[i],\n",
    "            'prev-word-is-one-char': len(tokens[i-1]) == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(punct_features(tokens, i), (i in boundaries))for i in range(1, len(tokens)-1)if tokens[i] in '.?!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'next-word-capitalized': True,\n",
       "   'prev-word': '29',\n",
       "   'punct': '.',\n",
       "   'prev-word-is-one-char': False},\n",
       "  True),\n",
       " ({'next-word-capitalized': True,\n",
       "   'prev-word': 'mr',\n",
       "   'punct': '.',\n",
       "   'prev-word-is-one-char': False},\n",
       "  False),\n",
       " ({'next-word-capitalized': True,\n",
       "   'prev-word': 'n',\n",
       "   'punct': '.',\n",
       "   'prev-word-is-one-char': True},\n",
       "  False),\n",
       " ({'next-word-capitalized': False,\n",
       "   'prev-word': 'group',\n",
       "   'punct': '.',\n",
       "   'prev-word-is-one-char': False},\n",
       "  True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using these featuresets, we can train and evaluate a punctuation classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936026936026936"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    ### 2.2 IDENTIFYING DIALOGUE ACT TYPE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  When processing dialogue, it can be useful to think of utterances as a type of action performed by the speaker.\n",
    "# This interpretation is most straightforward for performative statements such as \n",
    "# \"I forgive you\" or \"I bet you can't climb that hill.\" \n",
    "# dialogue act types, such as \"Statement,\" \"Emotion,\" \"ynQuestion\", and \"Continuer.\"\n",
    "# We can therefore use this data to build a classifier that can identify the dialogue act types for new instant messaging posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class'))for post in posts]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'contains(:)': True, 'contains(p)': True}, 'Emotion'),\n",
       " ({'contains(part)': True}, 'System'),\n",
       " ({'contains(hey)': True, 'contains(everyone)': True}, 'Greet'),\n",
       " ({'contains(ah)': True, 'contains(well)': True}, 'Statement'),\n",
       " ({'contains(nick)': True, 'contains(:10-19-20suser7)': True}, 'System'),\n",
       " ({'contains(10-19-20suser7)': True,\n",
       "   'contains(is)': True,\n",
       "   'contains(a)': True,\n",
       "   'contains(gay)': True,\n",
       "   'contains(name)': True,\n",
       "   'contains(.)': True},\n",
       "  'Accept'),\n",
       " ({'contains(.action)': True,\n",
       "   'contains(gives)': True,\n",
       "   'contains(10-19-20suser121)': True,\n",
       "   'contains(a)': True,\n",
       "   'contains(golf)': True,\n",
       "   'contains(clap)': True,\n",
       "   'contains(.)': True},\n",
       "  'System'),\n",
       " ({'contains(:)': True, 'contains())': True}, 'Emotion'),\n",
       " ({'contains(join)': True}, 'System'),\n",
       " ({'contains(hi)': True, 'contains(10-19-20suser59)': True}, 'Greet'),\n",
       " ({'contains(26/)': True,\n",
       "   'contains(m/)': True,\n",
       "   'contains(ky)': True,\n",
       "   'contains(women)': True,\n",
       "   'contains(that)': True,\n",
       "   'contains(are)': True,\n",
       "   'contains(nice)': True,\n",
       "   'contains(please)': True,\n",
       "   'contains(pm)': True,\n",
       "   'contains(me)': True},\n",
       "  'Statement'),\n",
       " ({'contains(join)': True}, 'System'),\n",
       " ({'contains(part)': True}, 'System'),\n",
       " ({'contains(there)': True,\n",
       "   'contains(ya)': True,\n",
       "   'contains(go)': True,\n",
       "   'contains(10-19-20suser7)': True},\n",
       "  'Statement'),\n",
       " ({'contains(do)': True,\n",
       "   \"contains(n't)\": True,\n",
       "   'contains(golf)': True,\n",
       "   'contains(clap)': True,\n",
       "   'contains(me)': True,\n",
       "   'contains(.)': True},\n",
       "  'Reject'),\n",
       " ({'contains(fuck)': True,\n",
       "   'contains(you)': True,\n",
       "   'contains(10-19-20suser121)': True,\n",
       "   'contains(:)': True,\n",
       "   'contains(@)': True},\n",
       "  'Reject'),\n",
       " ({'contains(whats)': True,\n",
       "   'contains(everyone)': True,\n",
       "   'contains(up)': True,\n",
       "   'contains(to)': True,\n",
       "   'contains(?)': True},\n",
       "  'whQuestion'),\n",
       " ({'contains(part)': True}, 'System'),\n",
       " ({'contains(part)': True}, 'System')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whQuestion'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(dialogue_act_features('how are you?'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greet'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(dialogue_act_features('hii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                ### 2.3 RECOGNIZING TEXT ENTAILMENT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTE is the task of determining whether a given piece of text T entails another text called the \"hypothesis\".\n",
    "# Here are a couple of examples:\n",
    "#    An example of a True TEXT ENTAILTAINMENT (text entails hypothesis) is:\n",
    "        \n",
    "#    text: If you help the needy, God will reward you.\n",
    "#    hypothesis: Giving money to a poor man has good consequences.\n",
    "\n",
    "#    An example of a False TEXT ENTAILTAINMENT (text contradicts hypothesis) is:\n",
    "        \n",
    "#    text: If you help the needy, God will reward you.\n",
    "#    hypothesis: Giving money to a poor man has no consequences.\n",
    "    \n",
    "#  We can treat RTE as a classification task, in which we try to predict the True/False label for each pair.\n",
    "#  It seems likely that successful approaches to this task will involve a combination of parsing,semantics and real world knowledge.\n",
    "#  RTE achieved reasonably good results with shallow analysis, based on similarity between the text and hypothesis at the word level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rte_features(rtepair):\n",
    "  # builds a bag of words for both text and hypothesis\n",
    "  # after throwing away some stopwords\n",
    "  extractor = nltk.RTEFeatureExtractor(rtepair)\n",
    "  return {\n",
    "    \"word_overlap\" : len(extractor.overlap(\"word\")),\n",
    "    \"word_hyp_extra\" : len(extractor.hyp_extra(\"word\")),\n",
    "    \"ne_overlap\" : len(extractor.overlap(\"ne\")),\n",
    "    \"ne_hyp_overlap\" : len(extractor.hyp_extra(\"ne\"))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_text_entailment():\n",
    "  rtepair = nltk.corpus.rte.pairs([\"rte3_dev.xml\"])[33]\n",
    "  extractor = nltk.RTEFeatureExtractor(rtepair)\n",
    "  # all important words in hypothesis is contained in text => entailment\n",
    "  print (\"text-words=\", extractor.text_words)\n",
    "  print (\"hyp-words=\", extractor.hyp_words)\n",
    "  #print (\"overlap(word)=\", extractor.overlap(\"word\"))\n",
    "  print (\"overlap(ne)=\", extractor.overlap(\"ne\"))\n",
    "  print (\"hyp_extra(word)=\", extractor.hyp_extra(\"word\"))\n",
    "  print (\"hyp_extra(ne)=\", extractor.hyp_extra(\"ne\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-words= {'together', 'central', 'that', 'Parviz', 'Asia', 'was', 'SCO', 'fight', 'association', 'Davudi', 'Soviet', 'meeting', 'China', 'representing', 'terrorism.', 'Shanghai', 'operation', 'Russia', 'binds', 'fledgling', 'Organisation', 'former', 'four', 'republics', 'Iran', 'at', 'Co'}\n",
      "hyp-words= {'member', 'China', 'SCO.'}\n",
      "overlap(ne)= {'China'}\n",
      "hyp_extra(word)= {'member'}\n",
      "hyp_extra(ne)= {'SCO.'}\n"
     ]
    }
   ],
   "source": [
    "recognize_text_entailment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                ### 2.4  SCALING UPTO LARGE DATAS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Python provides an excellent environment for performing basic text processing and feature extraction. \n",
    "    However, it is not able to perform the numerically intensive calculations required by machine learning methods \n",
    "    nearly as quickly as lower-level languages such as C.\n",
    "    \n",
    "     Thus, if you attempt to use the pure-Python machine learning implementations (such as nltk.NaiveBayesClassifier) \n",
    "     on large datasets, you may find that the learning algorithm takes an unreasonable amount of time and memory to complete.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
