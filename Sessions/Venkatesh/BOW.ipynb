{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What is a Bag-of-Words?\n",
    "\n",
    "A bag-of-words model, or BoW for short, is a way of extracting features from text for use in modeling, \n",
    "such as with machine learning algorithms.\n",
    "\n",
    "A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n",
    "1. A vocabulary of known words.\n",
    "2. A measure of the presence of known words.\n",
    "\n",
    "It is called a “bag” of words, because any information about the order or structure of words in the document is discarded. \n",
    "The model is only concerned with whether known words occur in the document, not where in the document.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example of the Bag-of-Words Model\n",
    "\n",
    "Step 1: Collect Data\n",
    "\n",
    "It was the best of times,\n",
    "it was the worst of times,\n",
    "it was the age of wisdom,\n",
    "it was the age of foolishness,\n",
    "\n",
    "Step 2: Design the Vocabulary\n",
    "\n",
    "Now we can make a list of all of the words in our model vocabulary.\n",
    "The unique words here (ignoring case and punctuation) are:\n",
    "\n",
    "“it”\n",
    "“was”\n",
    "“the”\n",
    "“best”\n",
    "“of”\n",
    "“times”\n",
    "“worst”\n",
    "“age”\n",
    "“wisdom”\n",
    "“foolishness”\n",
    "\n",
    "That is a vocabulary of 10 words from a corpus containing 24 words.\n",
    "\n",
    "Step 3: Create Document Vectors\n",
    "\n",
    "The scoring of the document would look as follows:\n",
    "\n",
    "“it” = 1\n",
    "“was” = 1\n",
    "“the” = 1\n",
    "“best” = 1\n",
    "“of” = 1\n",
    "“times” = 1\n",
    "“worst” = 0\n",
    "“age” = 0\n",
    "“wisdom” = 0\n",
    "“foolishness” = 0\n",
    "\n",
    "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
    "\n",
    "\"it was the worst of times\" = [1, 1, 1, 0, 1, 1, 1, 0, 0, 0]\n",
    "\"it was the age of wisdom\" = [1, 1, 1, 0, 1, 0, 0, 1, 1, 0]\n",
    "\"it was the age of foolishness\" = [1, 1, 1, 0, 1, 0, 0, 1, 0, 1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beans': 2, 'i': 12, 'was': 1, 'trying': 1, 'to': 8, 'explain': 1, 'somebody': 3, 'as': 1, 'we': 2, 'were': 2, 'flying': 1, 'in': 5, 'that': 4, 's': 3, 'corn': 1, 'and': 7, 'they': 1, 'very': 1, 'impressed': 1, 'at': 4, 'my': 1, 'agricultural': 1, 'knowledge': 1, 'please': 1, 'give': 1, 'it': 3, 'up': 1, 'for': 5, 'amaury': 1, 'once': 1, 'again': 1, 'outstanding': 2, 'introduction': 1, 'have': 3, 'a': 2, 'bunch': 1, 'of': 3, 'good': 1, 'friends': 1, 'here': 5, 'today': 2, 'including': 1, 'who': 4, 'served': 1, 'with': 1, 'is': 4, 'one': 1, 'the': 9, 'finest': 1, 'senators': 1, 'country': 1, 're': 1, 'lucky': 1, 'him': 1, 'your': 1, 'senator': 1, 'dick': 1, 'durbin': 1, 'also': 1, 'noticed': 1, 'by': 2, 'way': 1, 'former': 1, 'governor': 2, 'edgar': 1, 'haven': 1, 't': 2, 'seen': 1, 'long': 1, 'time': 1, 'somehow': 1, 'he': 2, 'has': 1, 'not': 1, 'aged': 1, 'great': 1, 'see': 1, 'you': 1, 'want': 2, 'thank': 1, 'president': 1, 'killeen': 1, 'everybody': 1, 'u': 1, 'system': 1, 'making': 1, 'possible': 1, 'me': 2, 'be': 1, 'am': 1, 'deeply': 1, 'honored': 1, 'paul': 1, 'douglas': 1, 'award': 1, 'being': 1, 'given': 1, 'set': 1, 'path': 1, 'so': 1, 'much': 1, 'public': 1, 'service': 1, 'illinois': 1, 'now': 1, 'start': 1, 'addressing': 1, 'elephant': 1, 'room': 1, 'know': 1, 'people': 1, 'are': 1, 'still': 1, 'wondering': 1, 'why': 1, 'didn': 1, 'speak': 1, 'commencement': 1}\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Preprossing\n",
    "import nltk \n",
    "import re \n",
    "import numpy as np \n",
    "  \n",
    "# execute the text here as : \n",
    "text = \"\"\"Beans. I was trying to explain to somebody as we were flying in, that’s corn. \n",
    "That’s beans. And they were very impressed at my agricultural knowledge. \n",
    "Please give it up for Amaury once again for that outstanding introduction. \n",
    "I have a bunch of good friends here today, including somebody who I served with, \n",
    "who is one of the finest senators in the country, and we’re lucky to have him, your Senator, \n",
    "Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, \n",
    "and somehow he has not aged and I have. And it’s great to see you, Governor. I want to thank President Killeen \n",
    "and everybody at the U of I System for making it possible for me to be here today. \n",
    "And I am deeply honored at the Paul Douglas Award that is being given to me. \n",
    "He is somebody who set the path for so much outstanding public service here in Illinois.\n",
    "Now, I want to start by addressing the elephant in the room. I know people are still \n",
    "wondering why I didn’t speak at the commencement.\"\"\"\n",
    "\n",
    "dataset = nltk.sent_tokenize(text) \n",
    "for i in range(len(dataset)): \n",
    "    dataset[i] = dataset[i].lower() \n",
    "    dataset[i] = re.sub(r'\\W', ' ', dataset[i]) \n",
    "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i])\n",
    "                        \n",
    "# Creating the Bag of Words model \n",
    "word2count = {}\n",
    "for data in dataset: \n",
    "    words = nltk.word_tokenize(data) \n",
    "    for word in words: \n",
    "        if word not in word2count.keys(): \n",
    "            word2count[word] = 1\n",
    "        else: \n",
    "            word2count[word] += 1\n",
    "print(word2count)\n",
    "\n",
    "                        \n",
    "X = [] \n",
    "for data in dataset: \n",
    "    vector = [] \n",
    "    for word in word2count: \n",
    "        if word in nltk.word_tokenize(data): \n",
    "            vector.append(1) \n",
    "        else: \n",
    "            vector.append(0) \n",
    "    X.append(vector) \n",
    "X = np.asarray(X)                    \n",
    "print(X)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
